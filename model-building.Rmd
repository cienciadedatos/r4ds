# Construcción de modelos

## Introducción

En el capítulo previo aprendimos como funcionan los modelos lineales, y aprendimos algunas herramientas básicas para entender lo que un modelo esta diciendo con sus datos. El capítulo previo se enfocó en simular conjunto de datos. Este capítulo se centrará en datos reales, mostrando como puedes progresivamente construir un modelo ayudando a entender los datos. 

Tomaremos ventaja del hecho que se puede pensar que un modelo particiona tus datos en patrones y residuos. Encontraremos patrones con visualizaciones, luego los haremos concretos y precisos con un modelo. Repetiremos luego el proceso, pero reemplazaremos la variable antigua con los residuos del modelo. El objetivo es pasar de un conocimiento implicito en la data a un conocimiento explicito en un modelo cuantitativo. Esto hace que sea mas facil aplicar nuevos dominios, y mas facil de usar para otros. 

Para un grande y complejo conjunto de datos esto será mucho trabajo. Sin duda hay enfoques alternativos - un enfoque de aprendizaje mas automatico es simplemente enfocarse en la capacidad predictiva del modelo. Ese enfoque tiende a producir cajas negras: el modelo hace muy bien su trabajo generando prediciones, pero no sabes porque. Esto es un enfoque totalmente razonable, pero lo hace dificil de aplicar el conocimiento del mundo real al modelo. Eso, a su vez, hace dificil evaluar si el modelo continuará o no funcionando a largo plazo, ya que los fundamentos cambian. Para la mayoria de los modelos, esperaría que usaras alguna combinacion de este enfoque y un enfoque clasico mas automatizado.

Es un desafio saber cuando detenerse. Tu necesitas averiguar cuando tu modelo es bastante bueno, y es poco probable que la investigacion adicional pagué. Me gusta especialmente esta cita del usuario Broseidon241: 

> Hace mucho tiempo en clases de arte, mi profesor me dijo "un artista necesita saber 
> cuando una pieza se termina. No puedes ajustar algo a la perfeccion - envuelvelo. 
> Si no te gusta, hazlo otra vez. O sino empieza algo nuevo". Mas tarde
> en la vida, yo escuché "Una pobre costurera comete muchos errores. Una buena costurera 
> trabaja duro para corregir esos errores. Una grandiosa costurera no tiene miedo de 
> tirar la prenda y empezar nuevamente."

-- Broseidon241, <https://www.reddit.com/r/datascience/comments/4irajq>

### Prerequisitos

Usaremos las mismas herramientas que en el capitulo anterior, pero agregaremos algunos datos reales: `diamonds` de ggplot2, y `flights` de nycflights13. También necesitaremos lubridate para trabajar con fechas/horas en `flights`.

```{r setup, message = FALSE}
library(tidyverse)
library(modelr)
options(na.action = na.warn)

library(nycflights13)
library(lubridate)
```

## ¿Porqué los diamantes de baja calidad son más caros? {#diamond-prices}

En el capitulo anterior vimos una sorprendente relacion entre la calidad de los diamantes y su precio: baja calidad de diamantes (cortes pobres, malos colores, y claridad inferior) tienen mas altos precios.

```{r dev = "png"}
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
ggplot(diamonds, aes(color, price)) + geom_boxplot()
ggplot(diamonds, aes(clarity, price)) + geom_boxplot()
```

Tener en cuenta que el peor diamante es J (ligero amarillo), y la peor claridad es I1 (inclusiones visibles a simple vista).

### Precio y Quilates

Parece que los diamantes de menor calidad tiene precios mas altos porque hay una importante variable de confusion: el peso (`carat`) del diamante. El peso del diamante es el factor individual mas importante para determinar el precio del diamante, y los diamantes de menor calidad tienden a ser mas grandes.

```{r}
ggplot(diamonds, aes(carat, price)) + 
  geom_hex(bins = 50)
```

Podemos hacer que sea más fácil ver cómo los otros atributos de un diamante afectan su `price` relativo al ajustar un modelo para separar el efecto de `carat`. Pero primero, hagamos algunos ajustes al conjunto de datos de diamantes para que sea más fácil trabajar con: 

1. foco en los diamantes mas pequeños que 2.5 quilates (99.7% de los datos)
1. Log-transformacion de variables quilate y precio.

```{r}
diamonds2 <- diamonds %>% 
  filter(carat <= 2.5) %>% 
  mutate(lprice = log2(price), lcarat = log2(carat))
```

Juntos, esos cambios hacen mas facil ver la relación entre `carat` y `price`:

```{r}
ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_hex(bins = 50)
```

La log-transformacion es particularmente util aqui porque hace que el patron sea lineal, y patrones lineales son mas faciles de usar.  Tomemos el proximo paso y eliminemos ese patron lineal fuerte. Primero hacemos explicito el patron ajustando el modelo:

```{r}
mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)
```

Luego observamos lo que el modelo nos dice. Tener en cuenta que devuelvo la transformacion de la prediccion, deshaciendo la log transformacion, para poder superponer las predicciones en los datos:

```{r}
grid <- diamonds2 %>% 
  data_grid(carat = seq_range(carat, 20)) %>% 
  mutate(lcarat = log2(carat)) %>% 
  add_predictions(mod_diamond, "lprice") %>% 
  mutate(price = 2 ^ lprice)

ggplot(diamonds2, aes(carat, price)) + 
  geom_hex(bins = 50) + 
  geom_line(data = grid, colour = "red", size = 1)
```

Eso nos dice algo interesante acerca de nuestros datos. Si creemos en nuestro modelo, los diamantes grandes son mucho mas baratos que lo esperado. Esto es probablemente porque no hay diamantes en estos datos que cuesten mas que $19,000.

Ahora podemos ver los residuos, lo cual comprueba que hemos eliminado el patron lineal fuerte:

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond, "lresid")

ggplot(diamonds2, aes(lcarat, lresid)) + 
  geom_hex(bins = 50)
```

Es importante destacar que ahora podemos volver a hacer nuestros graficos motivadores utilizando esos residuos en lugar de `price`. 

```{r dev = "png"}
ggplot(diamonds2, aes(cut, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(color, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(clarity, lresid)) + geom_boxplot()
```

Ahora vemos la relacion que esperabamos: a medida que aumenta la calidad del diamante, tambien lo hace su precio relativo. Para interpretar el eje `y`, necesitamos pensar que nos dicen los residuos, y en que escala estan. Un residuo de -1 indica que `lprice` era 1 unidad mas baja que la prediccion unicamente basada en su peso. $2^{-1}$ es 1/2, los puntos con un valor de -1 son la mitad del precio estimado, y los residuos con el valor 1 son el doble del precio predicho.

### Un modelo más complicado

Si quisieramos, podriamos continuar construyendo nuestro modelo, trasladando los efectos que hemos observado en el modelo para hacerlos explicitos. Por ejemplo, podriamos incluir `color`, `cut`, y `clarity` en el modelo para que tambien hagamos explicito el efecto de esas tres variables categoricas:

```{r}
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)
```

Este modelo ahora incluye cuatro predictores, This model now includes four predictors, por lo que es mas dificil de visualizar. Afortunadamente, todos ellos son actualmente independientes lo que significa que podemos graficarlos individualmente en cuatro graficos. Para hacer el proceso mas facil, vamos a usar el argumento `.model` para `data_grid`:

```{r}
grid <- diamonds2 %>% 
  data_grid(cut, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
grid

ggplot(grid, aes(cut, pred)) + 
  geom_point()
```

Si el modelo necesita variables que no hayas suministrado, `data_grid()` automaticamente los rellenará con el valor "typical". Para variables continuas, es usada la mediana, y variables categoricas usa el valor mas comun (o valores, si hay un empate).

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond2, "lresid2")

ggplot(diamonds2, aes(lcarat, lresid2)) + 
  geom_hex(bins = 50)
```

Este grafico indica que hay algunos diamantes con residuos bastante grandes - recuerde que un residuo de 2 indica que el diamante es 4x el precio que esperabamos. A menudo es util mirar los valores inusuales individualmente:

```{r}
diamonds2 %>% 
  filter(abs(lresid2) > 1) %>% 
  add_predictions(mod_diamond2) %>% 
  mutate(pred = round(2 ^ pred)) %>% 
  select(price, pred, carat:table, x:z) %>% 
  arrange(price)
```

Nada realmente interesante hasta aquí, pero probablemente valga la pena pasar tiempo considerando si esto indica un problema con nuestro modelo, o si hay errores en los datos. Si hay errores en los datos, esta podria ser una oportunidad para comprar diamantes que tienen un precio bajo incorrecto.

### Ejercicios

1.  En el grafico de `lcarat` vs. `lprice`, hay unas tiras verticales brillantes.
    ¿Que representan?

1.  Si `log(price) = a_0 + a_1 * log(carat)`, que eso dice acerca  
    la relacion entre `price` y `carat`?
    
1.  Extrae los diamantes que tiene muy alto y muy bajo residuos. 
    ¿Hau algo inusual en estos diamantes? ¿Son particularmente malos 
    o buenos?, o ¿crees que estos son errores de precio?

1.  ¿El modelo final, `mod_diamond2`, hace un buen trabajo prediciendo 
    precios de diamantes? ¿confiarias en que te diga cuanto gastar 
    si estuvieras comprando un diamante?

## ¿Que afecta el numero de vuelos diarias?

Trabajaremos a traves de un proceso similar para un conjunto de datos que parece aun mas simple a primera vista: el numero de vuelos que salen de NYC por dia. Este es un conjunto realmente pequeño de datos --- solo 365 filas y 2 columnas --- y no vamos a terminar con un modelo completamente realizado, pero como veras, los pasos en el camino nos ayudarán a entender mejor los datos. Comenzaremos contando  el numero de vuelos por dia y visualizandolos con ggplot2.

```{r}
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% 
  group_by(date) %>% 
  summarise(n = n())
daily

ggplot(daily, aes(date, n)) + 
  geom_line()
```

### Día de semana

Comprender la tendencia a largo plazo es un desafío porque hay un fuerte efecto en los dias de la semana que dominan los patrones sutiles. Comenzaremos mirando la distribucion de numero de vuelos por dia de la semana:

```{r}
daily <- daily %>% 
  mutate(wday = wday(date, label = TRUE))
ggplot(daily, aes(wday, n)) + 
  geom_boxplot()
```

Hay pocos vuelos los fin de semana porque la mayoria de los viajes es por negocios. El efecto es particularmente pronunciado el sabado: tu podrias algunas veces salir un domingo para una reunion un lunes en la mañana, pero esto es bastante raro que salgas un sabado ya que preferirias estar en casa con tu familia.

Una forma de eliminar este fuerte patron es usar un modelo. Primero, ajustaremos el modelo, y mostraremos sus predicciones superpuestas sobre los datos originales:

```{r}
mod <- lm(n ~ wday, data = daily)

grid <- daily %>% 
  data_grid(wday) %>% 
  add_predictions(mod, "n")

ggplot(daily, aes(wday, n)) + 
  geom_boxplot() +
  geom_point(data = grid, colour = "red", size = 4)
```

A continuación calculamos y visualizamos los residuos:

```{r}
daily <- daily %>% 
  add_residuals(mod)
daily %>% 
  ggplot(aes(date, resid)) + 
  geom_ref_line(h = 0) + 
  geom_line()
```

Notar el cambio en el eje Y: ahora estamos viendo la desviacion desde el numero de vuelos esperados, dados los dias de la semana. Este grafico es util porque ahora que removimos mucho de los grandes efectos dia-de-semana, nosotros podemos ver algo de los patrones mas sutiles que quedan:

1.  Nuestro modelo parece fallar a partir de junio: todavía se puede ver un 
    patron regular que nuestro modelo no ha capturado. Dibujando un diagrama con una 
    linea para cada dia de la semana se hace mas facil de ver:

    ```{r}
    ggplot(daily, aes(date, resid, colour = wday)) + 
      geom_ref_line(h = 0) + 
      geom_line()
    ```

    Nuestro modelo falla en predecir con precision el numero de vuelos los sabados: 
    durante el verano hay mas vuelos de los que esperamos, y durante el otoño 
    hay menos. Nosotros veremos como podemos capturar mejor este patron en la 
    siguiente seccion.

1.  Hay algunos dias con mucho menos vuelos que los esperados:

    ```{r}
    daily %>% 
      filter(resid < -100)
    ```

     Si tu estas familiarizado con los feriados publicos en Estados Unidos, puedes ver el dia de año nuevo,
     el 4 de julio, el dia de   accion de gracia y navidad. Hay algunos otros que parecen no 
     corresponder a feriados publicos. Trabajaras en esos en uno 
     de los ejercicios.
    
1.  Parece que hay una tendencia mas suave a largo plazo en el transcurso del año.
    Podemos destacar esa tendencia con `geom_smooth()`:

    ```{r}
    daily %>% 
      ggplot(aes(date, resid)) + 
      geom_ref_line(h = 0) + 
      geom_line(colour = "grey50") + 
      geom_smooth(se = FALSE, span = 0.20)
    ```

    Hay menos vuelos en enero (y diciembre), y mas en verano 
    (May-Sep). No podemos hacer mucho cuantitativamente con este patron, porque  
    solo tenemos un año de datos. Pero podemos usar nuestro conocimiento 
    para pensar en posibles explicaciones.

### Efecto estacional de Sábado

Primero abordaremos nuestra falla para predecir con exactitud el numero de vuelos el sabado. Un buen lugar para empezar es 
volver a los numeros en bruto, enfocandonos en el sabado:

```{r}
daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n)) + 
    geom_point() + 
    geom_line() +
    scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

(He usado tanto puntos como líneas para dejar más claro que son los datos y qué es la interpolación.)

Yo sospecho que este patron es causado por las vacaciones de invierno: mucha gente va de vacaciones en verano, y a las personas no les importa viajar un sabado en sus vacaciones. Al mirar este grafico, podemos suponer que las vacaciones de verano son de principio de  junio a finales de Agosto. Parece que se alinea bastante bien con los [Terminos escolares del estado](http://schools.nyc.gov/Calendar/2013-2014+School+Year+Calendars.htm): las vacaciones de verano en 2013 fueron del 26 de junio hasta el 9 de septiembre. 

¿Por qué hay mas vuelos los sabados en primavera que en otoño? Le pregunté a algunos amigos estadounidenses y ellos me dijeron que es menos comun planificar vacaciones familiares durante el otoño porque debido a los grandes feriados de accion de gracia y navidad. No tenemos los datos para estar seguros, pero parece la hipotesis mas razonable.

Vamos a crear una variable "term" que capture aproximadamente las 3 reglas de colegios, y verifique nuestro trabajo con un gráfico:

```{r}
term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall") 
  )
}

daily <- daily %>% 
  mutate(term = term(date)) 

daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n, colour = term)) +
  geom_point(alpha = 1/3) + 
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

(Modifiqué manualmente las fechas para obtener mejores cortes en el grafico. Usar una visualizacion para ayudarte a entender que funcion esta cumpliendo es una poderosa tecnica general.)

Es util ver como esta nueva variable afecta los otros dias de la semana:

```{r}
daily %>% 
  ggplot(aes(wday, n, colour = term)) +
    geom_boxplot()
```

Parece que hay una variacion significativa entre los terminos, por lo que es razonable ajustar los efectos por separado de los dias de semana para cada termino. Esto mejora nuestro modelo, pero no tanto como podriamos esperar:

```{r}
mod1 <- lm(n ~ wday, data = daily)
mod2 <- lm(n ~ wday * term, data = daily)

daily %>% 
  gather_residuals(without_term = mod1, with_term = mod2) %>% 
  ggplot(aes(date, resid, colour = model)) +
    geom_line(alpha = 0.75)
```

Podemos ver el problema al superponer las predicciones del modelo a los datos brutos:

```{r}
grid <- daily %>% 
  data_grid(wday, term) %>% 
  add_predictions(mod2, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, colour = "red") + 
  facet_wrap(~ term)
```

Nuestro modelo esta encontrando el efecto _mean_ , pero tenemos muchos valores atipicos grandes, por lo tanto la media tiende a estar lejos de los valores atipicos. Podemos aliviar este problema usando un modelo que es mas robusto a los efectos de los valores atipicos: `MASS::rlm()`. Esto reduce en gran medida el impacto de los valores atipicos en nuestras estimaciones, y proporciona un modelo que hace un buen trabajo eliminando el patron del dia de la semana:

```{r, warn = FALSE}
mod3 <- MASS::rlm(n ~ wday * term, data = daily)

daily %>% 
  add_residuals(mod3, "resid") %>% 
  ggplot(aes(date, resid)) + 
  geom_hline(yintercept = 0, size = 2, colour = "white") + 
  geom_line()
```

Ahora es mucho más fácil ver la tendencia a largo plazo, y los positivos y negativos valores atípicos.


### Variables calculadas

Si tu estas experimentando con muchos modelos y muchas visualizaciones, es una buena idea agrupar la creacion de variables en una funcion para que no haya posibilidad de aplicar accidentalmente transformaciones a diferentes lugares. Por ejemplo, podriamos escribir:

```{r}
compute_vars <- function(data) {
  data %>% 
    mutate(
      term = term(date), 
      wday = wday(date, label = TRUE)
    )
}
```

Otra opción es colocar las transformaciones directamente en la formula del modelo:

```{r}
wday2 <- function(x) wday(x, label = TRUE)
mod3 <- lm(n ~ wday2(date) * term(date), data = daily)
```

Cualquiera de los enfoques es razonable. Hacer que una variable transformada sea explicita es útil si quieres verificar tu trabajo, o usarlas en una visualización. Pero no puedes usar facilmente transformaciones (como splines) que devuelven multiples columnas. Incluir las transformaciones en el modelo hace la vida mas facil cuando se trabaja con diferentes conjuntos de datos porque el modelo es autonomo. 

### Epocas del año: un enfoque alternativo

En la sección anterior usamos nuestro conocimiento (como el término escolar de US afecta el viaje) para mejorar el modelo. Una alternativa es usar nuestro conocimiento explicito en el modelo para darle mas espacio para hablar. Podriamos usar un modelo mas flexible y permitir que capture el patron que nos interesa. Una tendencia lineal simple no es adecuada, por lo que podriamos intentar usar una spline natural para ajustarnos a una curva suave durante el año:

```{r}
library(splines)
mod <- MASS::rlm(n ~ wday * ns(date, 5), data = daily)

daily %>% 
  data_grid(wday, date = seq_range(date, n = 13)) %>% 
  add_predictions(mod) %>% 
  ggplot(aes(date, pred, colour = wday)) + 
    geom_line() +
    geom_point()
```

Vemos un patron fuerte en el numero de vuelos de los sabados. Esto es tranquilizador, porque tambien vimos ese patron en los datos brutos. Es una buena señal cuando obtienes la misma señal desde diferentes enfoques.


### Ejercicios

1.  Usa tus habilidades detestivescas de Google para intercambiar ideas sobre por qué hubo menos vuelos previstos el 20 de enero, 26 de mayo y 1 de septiembre. (Pista: todos tienen la misma explicacion.) ¿Como generalizarias esos días a otros años?

1.  ¿Que representan esos tres dias con altos residuos positivos?
    ¿Como generalizarias esos días a otros años?

    ```{r}
    daily %>% 
      top_n(3, resid)
    ```

1.  Crear una nueva variable que divida la variable `wday` en terminos, pero solo
    para sabados, es decir, deberia tener `Thurs`, `Fri`, pero `Sat-summer`, 
    `Sat-spring`, `Sat-fall`. ¿Como este modelo se compara con el modelo que tiene 
    la combinacion de `wday` y `term`?
    
1.  Crear una nueva variable `wday` que combina el dia de la semana, terminos 
    (para sabados), y feriados publicos. ¿a que se parecen los residuos 
    del modelo?

1.  ¿Que sucede si ajustamos un efecto de dia de la semana que varia mes por mes 
    (es decir, `n ~ wday * month`)? ¿Porqué esto no es muy útil? 

1.  ¿Que esperarias del modelo `n ~ wday + ns(date, 5)`?
    Sabiendo lo que sabes sobre los datos, ¿porqué esperarias que no sea 
    particularmente efectivo?
    
1.  Presumimos que las personas que salen los domingos son probablemente 
    viajeros de negocios quienes necesitan estar en algun lugar el lunes. Explora esa 
    hipotesis al ver como se rompe en funcion de la distancia y tiempo: si 
    es verdad, esperarias ver mas vuelos en la tarde del domingo a lugares que estan muy lejos.

1.  Es un poco frustante que el domingo y sabado tengan fines separados
    del grafico. Escribe una pequeña funcion para establecer los niveles del 
    factor para que la semana comience el lunes.

## Aprende mas sobre los modelos

Solo hemos dado una pincelada acerca de los modelos, pero es de esperar que hayas obtenido algunas herramientas simples, pero de uso general que puedes usar para mejorar tus propios analisis. !Está bien para empezar! Como has visto, incluso modelos muy simples pueden marcar una gran capacidad para desentrañar interacciones entre variables.

Estos capitulos de modelos son aun mas dogmaticos que el resto del libro. Yo enfoco el modelamiento desde una perspectiva diferente a los otros, y hay relativamente poco espacio dedicado a ello. El modelamiento realmente requiere un libro completo, asi que recomiendo que leas alguno de estos 3 libros:

* *Statistical Modeling: A Fresh Approach* by Danny Kaplan,
  <http://www.mosaic-web.org/go/StatisticalModeling/>. Este libro provee
  una introduccion suave al modelado, donde construyes por intuicion,
  herramientas matematicas, y habilidades de R en paralelo. el libro reemplaza 
  un tradicional curso de "introduction to statistics", propporcionando un plan de estudios 
  actualizado y reelevante para la ciencia de datos.

* *An Introduction to Statistical Learning* by Gareth James, Daniela Witten, 
  Trevor Hastie, and Robert Tibshirani, <http://www-bcf.usc.edu/~gareth/ISL/> 
  (Disponible en linea gratis). Este libro presenta una moderna familia de 
  tecnicas de modelamiento colectivamente conocidas como aprendizaje estadistico.
  Para una mas profunda comprensión de la matematica detras de los modelos, lee el clasico
  *Elements of Statistical Learning* por Trevor Hastie, Robert Tibshirani, y
  Jerome Friedman, <http://statweb.stanford.edu/~tibs/ElemStatLearn/> (También
  disponible en linea gratis).

* *Applied Predictive Modeling* por Max Kuhn and Kjell Johnson, 
  <http://appliedpredictivemodeling.com>. Este libro es un compañero del paquete 
  __caret__  y provee herramientas practicas para lidiar con desafíos de modelado predictivo.

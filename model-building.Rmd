# Construcción de modelos

## Introducción

En el capítulo previo aprendimos cómo funcionan los modelos lineales, y aprendimos algunas herramientas básicas para entender lo que un modelo está mostrando con sus datos. El capítulo previo se enfocó en simular conjunto de datos. Este capítulo se centrará en datos reales, mostrando como puedes progresivamente construir un modelo que te ayude a entender los datos. 

Tomaremos ventaja del hecho que se puede pensar que un modelo particiona tus datos en patrones y residuos. Encontraremos patrones con visualizaciones, luego los haremos concretos y precisos con un modelo. Repetiremos luego el proceso, pero reemplazaremos la variable antigua con los residuos del modelo. El objetivo es pasar de un conocimiento implícito en la data a un conocimiento explícito en un modelo cuantitativo. Esto hace que sea más fácil aplicar nuevos dominios, y más fácil de usar para otros. 

Para un grande y complejo conjunto de datos esto será mucho trabajo. Sin duda hay enfoques alternativos - un enfoque de aprendizaje más automático es simplemente enfocarse en la capacidad predictiva del modelo. Ese enfoque tiende a producir cajas negras: el modelo hace muy bien su trabajo generando predicciones, pero no sabes por qué. Esto es un enfoque totalmente razonable, pero es difícil de aplicar el conocimiento del mundo real al modelo. Eso, a su vez, hace difícil evaluar si el modelo continuará o no funcionando a largo plazo, ya que los fundamentos cambian. Para la mayoría de los modelos, esperaría que usaras alguna combinación de este enfoque y un enfoque clásico más automatizado.

Es un desafío saber cuándo detenerse. Tú necesitas averiguar cuándo tu modelo es suficientemente bueno, y cuando una inversion adicional vale la pena. Me gusta especialmente esta cita del usuario Broseidon241: 

> Hace mucho tiempo en clases de arte, mi profesor me dijo "Un artista necesita saber 
> cuándo una pieza está terminada. No puedes retocar algo a la perfección - termínalo. 
> Si no te gusta, hazlo otra vez. O sino empieza algo nuevo". En años posteriores,
> yo escuché "Una pobre costurera comete muchos errores. Una buena costurera 
> trabaja duro para corregir esos errores. Una grandiosa costurera no tiene miedo de 
> tirar la prenda y empezar nuevamente".

-- Broseidon241, <https://www.reddit.com/r/datascience/comments/4irajq>

### Prerrequisitos

Usaremos las mismas herramientas que en el capítulo anterior, pero agregaremos algunos conjuntos de datos reales: `diamantes` de ggplot2, y `vuelos` de nycflights13. También necesitaremos lubridate para trabajar con fechas/horas en `vuelos`.

```{r setup, message = FALSE}
library(tidyverse)
library(modelr)
options(na.action = na.warn)

library(nycflights13)
library(lubridate)
```

## ¿Por qué los diamantes de baja calidad son más caros? {#diamond-prices}

En el capítulo anterior vimos una sorprendente relación entre la calidad de los diamantes y su precio: baja calidad de diamantes (cortes pobres, colores malos, y claridad inferior) tienen más altos precios.

```{r dev = "png"}
ggplot(diamantes, aes(corte, precio)) + geom_boxplot()
ggplot(diamantes, aes(color, precio)) + geom_boxplot()
ggplot(diamantes, aes(claridad, precio)) + geom_boxplot()
```

Ten en cuenta que el peor diamante es J (amarillo claro), y la peor claridad es I1 (inclusiones visibles a simple vista).

### Precio y quilates

Pareciera que los diamantes de menor calidad tiene precios más altos porque hay una importante variable de confusión: el peso (`carat`) del diamante. El peso del diamante es el factor individual más importante para determinar el precio del diamante, y los diamantes de menor calidad tienden a ser más grandes.

```{r}
ggplot(diamantes, aes(quilates, precio)) + 
  geom_hex(bins = 50)
```

Podemos hacer que sea más fácil ver cómo los otros atributos de un diamante afectan su `precio` relativo al ajustar un modelo para separar el efecto de `quilates`. Pero primero, hagamos algunos ajustes al conjunto de datos de diamantes para que sea más fácil trabajar con: 

1. Foco en los diamantes más pequeños que 2.5 quilates (99.7% de los datos)
1. Log-transformación de variables quilate y precio.

```{r}
diamonds2 <- diamantes %>% 
  filter(quilates <= 2.5) %>% 
  mutate(lprice = log2(precio), lcarat = log2(quilates))
```

Juntos, esos cambios hacen más fácil ver la relación entre `quilates` y `precio`:

```{r}
ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_hex(bins = 50)
```

La log-transformación es particularmente util aquí porque hace que el patrón sea lineal, y patrones lineales son más fáciles de usar.  Tomemos el próximo paso y eliminemos ese patron lineal fuerte. Primero hacemos explicito el patrón ajustando el modelo:

```{r}
mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)
```

Luego observamos lo que el modelo nos dice. Ten en cuenta que vuelvo atrás la transformación de la predicción, deshaciendo la log transformación, para poder superponer las predicciones en los datos originales:

```{r}
grid <- diamonds2 %>% 
  data_grid(quilates = seq_range(quilates, 20)) %>% 
  mutate(lcarat = log2(quilates)) %>% 
  add_predictions(mod_diamond, "lprice") %>% 
  mutate(precio = 2 ^ lprice)

ggplot(diamonds2, aes(quilates, precio)) + 
  geom_hex(bins = 50) + 
  geom_line(data = grid, colour = "red", size = 1)
```

Eso nos dice algo interesante acerca de nuestros datos. Si creemos en nuestro modelo, los diamantes grandes son mucho más baratos que lo esperado. Esto es probablemente porque no hay diamantes en estos datos que cuesten más que US$19,000.

Ahora podemos ver los residuos, lo cual comprueba que hemos eliminado el patrón lineal fuerte:

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond, "lresid")

ggplot(diamonds2, aes(lcarat, lresid)) + 
  geom_hex(bins = 50)
```

Es importante destacar que ahora podemos volver a hacer nuestros gráficos motivadores utilizando esos residuos en lugar de `precio`. 

```{r dev = "png"}
ggplot(diamonds2, aes(corte, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(color, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(claridad, lresid)) + geom_boxplot()
```

Ahora vemos la relación que esperábamos: a medida que aumenta la calidad del diamante, también lo hace su precio relativo. Para interpretar el eje `y`, necesitamos pensar que nos dicen los residuos, y en que escala estan. Un residuo de -1 indica que `lprice` era 1 unidad más baja que la predicción únicamente basada en su peso. $2^{-1}$ es 1/2, los puntos con un valor de -1 son la mitad del precio estimado, y los residuos con el valor 1 son el doble del precio predicho.

### Un modelo más complicado

Si quisiéramos, podríamos continuar construyendo nuestro modelo, traspasando los resultados que hemos observado en el modelo para hacerlos explícitos. Por ejemplo, podriamos incluir `color`, `corte`, y `claridad` en el modelo para que también hagamos explícito el efecto de esas tres variables categóricas:

```{r}
mod_diamond2 <- lm(lprice ~ lcarat + color + corte + claridad, data = diamonds2)
```

Este modelo ahora incluye cuatro predictores, por lo que es más difícil de visualizar. Afortunadamente, todos ellos son actualmente independientes lo que significa que podemos graficarlos individualmente en cuatro gráficos. Para hacer el proceso más fácil, vamos a usar el argumento `.model` para `data_grid`:

```{r}
grid <- diamonds2 %>% 
  data_grid(corte, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
grid

ggplot(grid, aes(corte, pred)) + 
  geom_point()
```

Si el modelo necesita variables que no hayas suministrado, `data_grid()` automáticamente los rellenará con el valor "typical". Para variables continuas, se usa la mediana, y para variables categóricas se usa el valor más común (o valores, si hay un empate).

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond2, "lresid2")

ggplot(diamonds2, aes(lcarat, lresid2)) + 
  geom_hex(bins = 50)
```

Este gráfico indica que hay algunos diamantes con residuos bastante grandes - recuerda que un residuo de 2 indica que el diamante es 4x el precio que esperábamos. A menudo es útil mirar los valores inusuales individualmente:

```{r}
diamonds2 %>% 
  filter(abs(lresid2) > 1) %>% 
  add_predictions(mod_diamond2) %>% 
  mutate(pred = round(2 ^ pred)) %>% 
  select(precio, pred, carat:table, x:z) %>% 
  arrange(precio)
```

Hasta aquí nada realmente interesante, pero probablemente valga la pena pasar tiempo considerando si esto significa un problema con nuestro modelo, o si hay errores en los datos. Si hay errores en los datos, esta podría ser una oportunidad para comprar diamantes que tienen un precio bajo incorrecto.

### Ejercicios

1.  En el gráfico de `lcarat` vs. `lprice`, hay unas tiras verticales brillantes.
    ¿Que representan?

1.  Si `log(precio) = a_0 + a_1 * log(quilates)`, ¿que dice eso acerca  
    la relación entre `precio` y `quilates`?
    
1.  Extrae los diamantes que tiene muy alto y bajo residuos. 
    ¿Hay algo inusual en estos diamantes? ¿Son particularmente malos 
    o buenos?, o ¿Crees que estos son errores de precio?

1.  ¿El modelo final, `mod_diamond2`, hace un buen trabajo prediciendo 
    precios de diamantes? ¿Confiarías en que te diga cuanto gastar 
    si estuvieras comprando un diamante?

## ¿Que afecta el número de vuelos diarios?

Trabajaremos a través de un proceso similar para un conjunto de datos que parece aún más simple a primera vista: el número de vuelos que salen de NYC por día. Este es un conjunto realmente pequeño de datos --- solo 365 filas y 2 columnas --- y no vamos a terminar con un modelo completamente realizado, pero como veras, los pasos en el camino nos ayudarán a entender mejor los datos. Comenzaremos contando  el número de vuelos por día y visualizándolos con ggplot2.

```{r}
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% 
  group_by(date) %>% 
  summarise(n = n())
daily

ggplot(daily, aes(date, n)) + 
  geom_line()
```

### Día de semana

Comprender la tendencia a largo plazo es un desafío porque hay un fuerte efecto en los días de la semana que dominan los patrones sutiles. Comenzaremos mirando la distribución de número de vuelos por día de la semana:

```{r}
daily <- daily %>% 
  mutate(wday = wday(date, label = TRUE))
ggplot(daily, aes(wday, n)) + 
  geom_boxplot()
```

Hay pocos vuelos los fines de semana porque la mayoría de los viajes son por negocios. El efecto es particularmente pronunciado el sábado: tu podrías algunas veces salir un domingo para una reunión un lunes en la mañana, pero esto es bastante raro que salgas un sábado ya que preferirías estar en casa con tu familia.

Una forma de eliminar este fuerte patrón es usar un modelo. Primero, ajustaremos el modelo, y mostraremos sus predicciones superpuestas sobre los datos originales:

```{r}
mod <- lm(n ~ wday, data = daily)

grid <- daily %>% 
  data_grid(wday) %>% 
  add_predictions(mod, "n")

ggplot(daily, aes(wday, n)) + 
  geom_boxplot() +
  geom_point(data = grid, colour = "red", size = 4)
```

A continuación calculamos y visualizamos los residuos:

```{r}
daily <- daily %>% 
  add_residuals(mod)
daily %>% 
  ggplot(aes(date, resid)) + 
  geom_ref_line(h = 0) + 
  geom_line()
```

Notar el cambio en el eje Y: ahora estamos viendo la desviación desde el número de vuelos esperados, dados los días de la semana. Este gráfico es útil porque ahora que removimos mucho de los grandes efectos día-de-semana, nosotros podemos ver algo de los patrones más sutiles que quedan:

1.  Nuestro modelo parece fallar a partir de junio: todavía se puede ver un 
    patrón regular que nuestro modelo no ha capturado. Dibujando un diagrama con una 
    línea para cada día de la semana se hace más facil de ver:

    ```{r}
    ggplot(daily, aes(date, resid, colour = wday)) + 
      geom_ref_line(h = 0) + 
      geom_line()
    ```

    Nuestro modelo falla en predecir con precisión el número de vuelos los sábados: 
    durante el verano hay más vuelos de los que esperamos, y durante el otoño 
    hay menos. Nosotros veremos como podemos capturar mejor este patrón en la 
    siguiente sección.

1.  Hay algunos días con mucho menos vuelos que los esperados:

    ```{r}
    daily %>% 
      filter(resid < -100)
    ```

     Si tú estas familiarizado con los feriados públicos en Estados Unidos, podrías reconocer los días de año nuevo,
     el 4 de julio, el día de Acción de Gracia y Navidad. Hay algunos otros que parecen no 
     corresponder a feriados públicos. Trabajarás en uno de esos ejercicios.
    
1.  Parece que hay una tendencia más suave a largo plazo en el transcurso del año.
    Podemos destacar esa tendencia con `geom_smooth()`:

    ```{r}
    daily %>% 
      ggplot(aes(date, resid)) + 
      geom_ref_line(h = 0) + 
      geom_line(colour = "grey50") + 
      geom_smooth(se = FALSE, span = 0.20)
    ```

    Hay menos vuelos en enero (y diciembre), y más en verano 
    (May-Sep). No podemos hacer mucho cuantitativamente con este patrón, porque  
    sólo tenemos un año de datos. Pero podemos usar nuestro conocimiento 
    para pensar en posibles explicaciones.

### Efecto estacional de sábado

Primero abordaremos nuestra falla para predecir con exactitud el número de vuelos el sábado. Un buen lugar para empezar es 
volver a los números originales, enfocándonos en el sábado:

```{r}
daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n)) + 
    geom_point() + 
    geom_line() +
    scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

(He usado tanto puntos como líneas para dejar más claro que son los datos y qué es la interpolación).

Yo sospecho que este patrón es causado por las vacaciones de invierno: mucha gente va de vacaciones en verano, y a las personas no les importa viajar un sábado en sus vacaciones. Al mirar este gráfico, podemos suponer que las vacaciones de verano son de principio de  junio a finales de agosto. Parece que se alinea bastante bien con los [Reglamentos escolares del estado](http://schools.nyc.gov/Calendar/2013-2014+School+Year+Calendars.htm): las vacaciones de verano en 2013 fueron del 26 de junio hasta el 9 de septiembre. 

¿Por qué hay más vuelos los sábados en primavera que en otoño? Le pregunté a algunos amigos estadounidenses y ellos me dijeron que es menos común planificar vacaciones familiares durante el otoño porque debido a los grandes feriados de Acción de Gracia y Navidad. No tenemos los datos para estar seguros, pero parece la hipótesis más razonable.

Vamos a crear una variable "term" que capture aproximadamente las 3 reglas los colegios, y verifique nuestro trabajo con un gráfico:

```{r}
term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall") 
  )
}

daily <- daily %>% 
  mutate(term = term(date)) 

daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n, colour = term)) +
  geom_point(alpha = 1/3) + 
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

(Modifiqué manualmente las fechas para obtener mejores cortes en el gráfico. Usar una visualización para ayudarte a entender que función esta cumpliendo es una poderosa técnica general).

Es útil ver como esta nueva variable afecta los otros días de la semana:

```{r}
daily %>% 
  ggplot(aes(wday, n, colour = term)) +
    geom_boxplot()
```

Parece que hay una variación significativa entre los términos, por lo que es razonable ajustar los efectos por separado de los días de semana para cada término. Esto mejora nuestro modelo, pero no tanto como podríamos esperar:

```{r}
mod1 <- lm(n ~ wday, data = daily)
mod2 <- lm(n ~ wday * term, data = daily)

daily %>% 
  gather_residuals(without_term = mod1, with_term = mod2) %>% 
  ggplot(aes(date, resid, colour = model)) +
    geom_line(alpha = 0.75)
```

Podemos ver el problema al superponer las predicciones del modelo a los datos brutos:

```{r}
grid <- daily %>% 
  data_grid(wday, term) %>% 
  add_predictions(mod2, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, colour = "red") + 
  facet_wrap(~ term)
```

Nuestro modelo esta encontrando el efecto _mean_ , pero tenemos muchos valores atípicos grandes, por lo tanto la media tiende a estar lejos de los valores atípicos. Podemos aliviar este problema usando un modelo que es más robusto a los efectos de los valores atípicos: `MASS::rlm()`. Esto reduce en gran medida el impacto de los valores atípicos en nuestras estimaciones, y proporciona un modelo que hace un buen trabajo eliminando el patrón del día de la semana:

```{r, warn = FALSE}
mod3 <- MASS::rlm(n ~ wday * term, data = daily)

daily %>% 
  add_residuals(mod3, "resid") %>% 
  ggplot(aes(date, resid)) + 
  geom_hline(yintercept = 0, size = 2, colour = "white") + 
  geom_line()
```

Ahora es mucho más fácil ver la tendencia a largo plazo, los positivos y negativos valores atípicos.


### Variables calculadas

Si estas experimentando con muchos modelos y muchas visualizaciones, es una buena idea agrupar la creación de variables en una función para que no haya posibilidad de aplicar accidentalmente transformaciones a diferentes lugares. Por ejemplo, podríamos escribir:

```{r}
compute_vars <- function(data) {
  data %>% 
    mutate(
      term = term(date), 
      wday = wday(date, label = TRUE)
    )
}
```

Otra opción es colocar las transformaciones directamente en la fórmula del modelo:

```{r}
wday2 <- function(x) wday(x, label = TRUE)
mod3 <- lm(n ~ wday2(date) * term(date), data = daily)
```

Cualquiera de los enfoques es razonable. Hacer que una variable transformada sea explicita es útil si quieres verificar tu trabajo, o usarlas en una visualización. Pero no puedes usar fácilmente transformaciones (como splines) que devuelven múltiples columnas. Incluir las transformaciones en el modelo hace la vida más fácil cuando se trabaja con diferentes conjuntos de datos porque el modelo es autónomo. 

### Epocas del año: un enfoque alternativo

En la sección anterior usamos nuestro conocimiento (como el reglamento escolar de Estados Unidos afecta el viaje) para mejorar el modelo. Una alternativa es utilizar nuestro conocimiento explícito en el modelo para darle más espacio para hablar. Podríamos utilizar un modelo más flexible y permitir que capture el patrón que nos interesa. Una tendencia lineal simple no es adecuada, por lo que podríamos intentar usar una spline natural para ajustarnos a una curva suave durante el año:

```{r}
library(splines)
mod <- MASS::rlm(n ~ wday * ns(date, 5), data = daily)

daily %>% 
  data_grid(wday, date = seq_range(date, n = 13)) %>% 
  add_predictions(mod) %>% 
  ggplot(aes(date, pred, colour = wday)) + 
    geom_line() +
    geom_point()
```

Vemos un patrón fuerte en el número de vuelos de los sábados. Esto es tranquilizador, porque también vimos ese patrón en los datos brutos. Es una buena señal cuando obtienes la misma señal desde diferentes enfoques.


### Ejercicios

1.  Usa tus habilidades detestivescas de Google para intercambiar ideas sobre por qué hubo menos vuelos previstos el 20 de enero, 26 de mayo y 1 de septiembre. (Pista: todos tienen la misma explicación.) ¿Cómo generalizarías esos días a otros años?

1.  ¿Qué representan esos tres días con altos residuos positivos?
    ¿Cómo generalizarias esos días a otros años?

    ```{r}
    daily %>% 
      top_n(3, resid)
    ```

1.  Crea una nueva variable que divida la variable `wday` en términos, pero sólo
    para sábados, es decir, debería tener `Thurs`, `Fri`, pero `Sat-summer`, 
    `Sat-spring`, `Sat-fall`. ¿Cómo este modelo se compara con el modelo que tiene 
    la combinación de `wday` y `term`?
    
1.  Crea una nueva variable `wday` que combina el día de la semana, términos 
    (para sábados), y feriados públicos. ¿a qué se parecen los residuos 
    del modelo?

1.  ¿Qué sucede si ajustamos un efecto de día de la semana que varía mes por mes 
    (es decir, `n ~ wday * month`)? ¿Por qué esto no es muy útil? 

1.  ¿Que esperarías del modelo `n ~ wday + ns(date, 5)`?
    Sabiendo lo que sabes sobre los datos, ¿porqué esperarias que no sea 
    particularmente efectivo?
    
1.  Presumimos que las personas que salen los domingos son probablemente 
    viajeros de negocios quienes necesitan estar en algun lugar el lunes. Explora esa 
    hipótesis al ver cómo se rompe en función de la distancia y tiempo: si 
    es verdad, esperarías ver más vuelos en la tarde del domingo a lugares que estan muy lejos.

1.  Es un poco frustante que el domingo y sábado tengan fines separados
    del gráfico. Escribe una pequeña función para establecer los niveles del 
    factor para que la semana comience el lunes.

## Aprende más sobre los modelos

Solo hemos dado una pincelada acerca de los modelos, pero es de esperar que hayas obtenido algunas herramientas simples, pero de uso general que puedes usar para mejorar tus propios análisis. !Está bien para empezar! Como has visto, incluso modelos muy simples pueden marcar una gran capacidad para desentrañar interacciones entre variables.

Estos capítulos de modelos son aún más dogmáticos que el resto del libro. Yo enfoco el modelamiento desde una perspectiva diferente a los otros, y hay relativamente poco espacio dedicado a ello. El modelamiento realmente requiere un libro completo, así que recomiendo que leas alguno de estos 3 libros:

* *Statistical Modeling: A Fresh Approach* by Danny Kaplan,
  <http://www.mosaic-web.org/go/StatisticalModeling/>. Este libro provee
  una introducción suave al modelado, donde construyes por intuición,
  herramientas matemáticas, y habilidades de R en paralelo. el libro reemplaza 
  un tradicional curso de "introduction to statistics", proporcionando un plan de estudios 
  actualizado y relevante para la ciencia de datos.

* *An Introduction to Statistical Learning* by Gareth James, Daniela Witten, 
  Trevor Hastie, and Robert Tibshirani, <http://www-bcf.usc.edu/~gareth/ISL/> 
  (Disponible en línea gratis). Este libro presenta una moderna familia de 
  técnicas de modelamiento colectivamente conocidas como aprendizaje estadístico.
  Para una más profunda comprensión de la matemática detrás de los modelos, lee el clásico
  *Elements of Statistical Learning* por Trevor Hastie, Robert Tibshirani, y
  Jerome Friedman, <http://statweb.stanford.edu/~tibs/ElemStatLearn/> (También
  disponible en línea gratis).

* *Applied Predictive Modeling* por Max Kuhn and Kjell Johnson, 
  <http://appliedpredictivemodeling.com>. Este libro es un compañero del paquete 
  __caret__  y provee herramientas prácticas para lidiar con desafíos de modelado predictivo.

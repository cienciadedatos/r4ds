# Construcción de modelos

## Introducción

En el capítulo previo aprendimos como funcionan los modelos lineales, y aprendimos algunas herramientas básicas para entender lo que un modelo esta diciendo con sus datos. El capítulo previo se enfocó en simular conjunto de datos. Este capítulo se centrará en datos reales, mostrando como puedes progresivamente construir un modelo ayudando a entender los datos. 

Tomaremos ventaja del hecho que se puede pensar que un modelo particiona tus datos en patrones y residuos. Encontraremos patrones con visualizaciones, luego los haremos concretos y precisos con un modelo. Repetiremos luego el proceso, pero reemplazaremos la variable antigua con los residuos del modelo. El objetivo es pasar de un conocimiento implicito en la data a un conocimiento explicito en un modelo cuantitativo. Esto hace que sea mas facil aplicar nuevos dominios, y mas facil de usar para otros. 

Para un grande y complejo conjunto de datos esto será mucho trabajo. Sin duda hay enfoques alternativos - un enfoque de aprendizaje mas automatico es simplemente enfocarse en la capacidad predictiva del modelo. Ese enfoque tiende a producir cajas negras: el modelo hace muy bien su trabajo generando prediciones, pero no sabes porque. Esto es un enfoque totalmente razonable, pero lo hace dificil de aplicar el conocimiento del mundo real al modelo. Eso, a su vez, hace dificil evaluar si el modelo continuará o no funcionando a largo plazo, ya que los fundamentos cambian. Para la mayoria de los modelos, esperaría que usaras alguna combinacion de este enfoque y un enfoque clasico mas automatizado.

Es un desafio saber cuando detenerse. Tu necesitas averiguar cuando tu modelo es bastante bueno, y es poco probable que la investigacion adicional pagué. Me gusta especialmente esta cita del usuario Broseidon241: 

> Hace mucho tiempo en clases de arte, mi profesor me dijo "un artista necesita saber 
> cuando una pieza se termina. No puedes ajustar algo a la perfeccion - envuelvelo. 
> Si no te gusta, hazlo otra vez. O sino empieza algo nuevo". Mas tarde
> en la vida, yo escuché "Una pobre costurera comete muchos errores. Una buena costurera 
> trabaja duro para corregir esos errores. Una grandiosa costurera no tiene miedo de 
> tirar la prenda y empezar nuevamente."

-- Broseidon241, <https://www.reddit.com/r/datascience/comments/4irajq>

### Prerequisitos

Usaremos las mismas herramientas que en el capitulo anterior, pero agregaremos algunos datos reales: `diamonds` de ggplot2, y `flights` de nycflights13. También necesitaremos lubridate para trabajar con fechas/horas en `flights`.

```{r setup, message = FALSE}
library(tidyverse)
library(modelr)
options(na.action = na.warn)

library(nycflights13)
library(lubridate)
```

## ¿Porqué los diamantes de baja calidad son más caros? {#diamond-prices}

En el capitulo anterior vimos una sorprendente relacion entre la calidad de los diamantes y su precio: baja calidad de diamantes (cortes pobres, malos colores, y claridad inferior) tienen mas altos precios.

```{r dev = "png"}
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
ggplot(diamonds, aes(color, price)) + geom_boxplot()
ggplot(diamonds, aes(clarity, price)) + geom_boxplot()
```

Tener en cuenta que el peor diamante es J (ligero amarillo), y la peor claridad es I1 (inclusiones visibles a simple vista).

### Precio y Quilates

Parece que los diamantes de menor calidad tiene precios mas altos porque hay una importante variable de confusion: el peso (`carat`) del diamante. El peso del diamante es el factor individual mas importante para determinar el precio del diamante, y los diamantes de menor calidad tienden a ser mas grandes.

```{r}
ggplot(diamonds, aes(carat, price)) + 
  geom_hex(bins = 50)
```

Podemos hacer que sea más fácil ver cómo los otros atributos de un diamante afectan su `price` relativo al ajustar un modelo para separar el efecto de `carat`. Pero primero, hagamos algunos ajustes al conjunto de datos de diamantes para que sea más fácil trabajar con: 

1. foco en los diamantes mas pequeños que 2.5 quilates (99.7% de los datos)
1. Log-transformacion de variables quilate y precio.

```{r}
diamonds2 <- diamonds %>% 
  filter(carat <= 2.5) %>% 
  mutate(lprice = log2(price), lcarat = log2(carat))
```

Juntos, esos cambios hacen mas facil ver la relación entre `carat` y `price`:

```{r}
ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_hex(bins = 50)
```

La log-transformacion es particularmente util aqui porque hace que el patron sea lineal, y patrones lineales son mas faciles de usar.  Tomemos el proximo paso y eliminemos ese patron lineal fuerte. Primero hacemos explicito el patron ajustando el modelo:

```{r}
mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)
```

Luego observamos lo que el modelo nos dice. Tener en cuenta que devuelvo la transformacion de la prediccion, deshaciendo la log transformacion, para poder superponer las predicciones en los datos:

```{r}
grid <- diamonds2 %>% 
  data_grid(carat = seq_range(carat, 20)) %>% 
  mutate(lcarat = log2(carat)) %>% 
  add_predictions(mod_diamond, "lprice") %>% 
  mutate(price = 2 ^ lprice)

ggplot(diamonds2, aes(carat, price)) + 
  geom_hex(bins = 50) + 
  geom_line(data = grid, colour = "red", size = 1)
```

Eso nos dice algo interesante acerca de nuestros datos. Si creemos en nuestro modelo, los diamantes grandes son mucho mas baratos que lo esperado. Esto es probablemente porque no hay diamantes en estos datos que cuesten mas que $19,000.

Ahora podemos ver los residuos, lo cual comprueba que hemos eliminado el patron lineal fuerte:

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond, "lresid")

ggplot(diamonds2, aes(lcarat, lresid)) + 
  geom_hex(bins = 50)
```

Es importante destacar que ahora podemos volver a hacer nuestros graficos motivadores utilizando esos residuos en lugar de `price`. 

```{r dev = "png"}
ggplot(diamonds2, aes(cut, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(color, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(clarity, lresid)) + geom_boxplot()
```

Ahora vemos la relacion que esperabamos: a medida que aumenta la calidad del diamante, tambien lo hace su precio relativo. Para interpretar el eje `y`, necesitamos pensar que nos dicen los residuos, y en que escala estan. Un residuo de -1 indica que `lprice` era 1 unidad mas baja que la prediccion unicamente basada en su peso. $2^{-1}$ es 1/2, los puntos con un valor de -1 son la mitad del precio estimado, y los residuos con el valor 1 son el doble del precio predicho.

### Un modelo más complicado

Si quisieramos, podriamos continuar construyendo nuestro modelo, trasladando los efectos que hemos observado en el modelo para hacerlos explicitos. Por ejemplo, podriamos incluir `color`, `cut`, y `clarity` en el modelo para que tambien hagamos explicito el efecto de esas tres variables categoricas:

```{r}
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)
```

Este modelo ahora incluye cuatro predictores, This model now includes four predictors, por lo que es mas dificil de visualizar. Afortunadamente, todos ellos son actualmente independientes lo que significa que podemos graficarlos individualmente en cuatro graficos. Para hacer el proceso mas facil, vamos a usar el argumento `.model` para `data_grid`:

```{r}
grid <- diamonds2 %>% 
  data_grid(cut, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
grid

ggplot(grid, aes(cut, pred)) + 
  geom_point()
```

Si el modelo necesita variables que no hayas suministrado, `data_grid()` automaticamente los rellenará con el valor "typical". Para variables continuas, es usada la mediana, y variables categoricas usa el valor mas comun (o valores, si hay un empate).

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond2, "lresid2")

ggplot(diamonds2, aes(lcarat, lresid2)) + 
  geom_hex(bins = 50)
```

Este grafico indica que hay algunos diamantes con residuos bastante grandes - recuerde que un residuo de 2 indica que el diamante es 4x el precio que esperabamos. A menudo es util mirar los valores inusuales individualmente:

```{r}
diamonds2 %>% 
  filter(abs(lresid2) > 1) %>% 
  add_predictions(mod_diamond2) %>% 
  mutate(pred = round(2 ^ pred)) %>% 
  select(price, pred, carat:table, x:z) %>% 
  arrange(price)
```

Nada realmente interesante hasta aquí, pero probablemente valga la pena pasar tiempo considerando si esto indica un problema con nuestro modelo, o si hay errores en los datos. Si hay errores en los datos, esta podria ser una oportunidad para comprar diamantes que tienen un precio bajo incorrecto.

### Ejercicios

1.  En el grafico de `lcarat` vs. `lprice`, hay unas tiras verticales brillantes.
    ¿Que representan?

1.  Si `log(price) = a_0 + a_1 * log(carat)`, que eso dice acerca  
    la relacion entre `price` y `carat`?
    
1.  Extrae los diamantes que tiene muy alto y muy bajo residuos. 
    ¿Hau algo inusual en estos diamantes? ¿Son particularmente malos 
    o buenos?, o ¿crees que estos son errores de precio?

1.  ¿El modelo final, `mod_diamond2`, hace un buen trabajo prediciendo 
    precios de diamantes? ¿confiarias en que te diga cuanto gastar 
    si estuvieras comprando un diamante?

## ¿Que afecta el numero de vuelos diarias?

Trabajaremos a traves de un proceso similar para un conjunto de datos que parece aun mas simple a primera vista: el numero de vuelos que salen de NYC por dia. Este es un conjunto realmente pequeño de datos --- solo 365 filas y 2 columnas --- y no vamos a terminar con un modelo completamente realizado, pero como veras, los pasos en el camino nos ayudarán a entender mejor los datos. Comenzaremos contando  el numero de vuelos por dia y visualizandolos con ggplot2.

```{r}
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% 
  group_by(date) %>% 
  summarise(n = n())
daily

ggplot(daily, aes(date, n)) + 
  geom_line()
```

### Día de semana

Comprender la tendencia a largo plazo es un desafío porque hay un fuerte efecto en los dias de la semana que dominan los patrones sutiles. Comenzaremos mirando la distribucion de numero de vuelos por dia de la semana:

```{r}
daily <- daily %>% 
  mutate(wday = wday(date, label = TRUE))
ggplot(daily, aes(wday, n)) + 
  geom_boxplot()
```

Hay pocos vuelos los fin de semana porque la mayoria de los viajes es por negocios. El efecto es particularmente pronunciado el sabado: tu podrias algunas veces salir un domingo para una reunion un lunes en la mañana, pero esto es bastante raro que salgas un sabado ya que preferirias estar en casa con tu familia.

Una forma de eliminar este fuerte patron es usar un modelo. Primero, ajustaremos el modelo, y mostraremos sus predicciones superpuestas sobre los datos originales:

```{r}
mod <- lm(n ~ wday, data = daily)

grid <- daily %>% 
  data_grid(wday) %>% 
  add_predictions(mod, "n")

ggplot(daily, aes(wday, n)) + 
  geom_boxplot() +
  geom_point(data = grid, colour = "red", size = 4)
```

A continuación calculamos y visualizamos los residuos:

```{r}
daily <- daily %>% 
  add_residuals(mod)
daily %>% 
  ggplot(aes(date, resid)) + 
  geom_ref_line(h = 0) + 
  geom_line()
```

Notar el cambio en el eje Y: ahora estamos viendo la desviacion desde el numero de vuelos esperados, dados los dias de la semana. Este grafico es util porque ahora que removimos mucho de los grandes efectos dia-de-semana, nosotros podemos ver algo de los patrones mas sutiles que quedan:

1.  Nuestro modelo parece fallar a partir de junio: todavía se puede ver un 
    patron regular que nuestro modelo no ha capturado. Dibujando un diagrama con una 
    linea para cada dia de la semana se hace mas facil de ver:

    ```{r}
    ggplot(daily, aes(date, resid, colour = wday)) + 
      geom_ref_line(h = 0) + 
      geom_line()
    ```

    Nuestro modelo falla en predecir con precision el numero de vuelos los sabados: 
    durante el verano hay mas vuelos de los que esperamos, y durante el otoño 
    hay menos. Nosotros veremos como podemos capturar mejor este patron en la 
    siguiente seccion.

1.  Hay algunos dias con mucho menos vuelos que los esperados:

    ```{r}
    daily %>% 
      filter(resid < -100)
    ```

     Si tu estas familiarizado con los feriados publicos en Estados Unidos, puedes ver el dia de año nuevo,
     el 4 de julio, el dia de   accion de gracia y navidad. Hay algunos otros que parecen no 
     corresponder a feriados publicos. Trabajaras en esos en uno 
     de los ejercicios.
    
1.  Parece que hay una tendencia mas suave a largo plazo en el transcurso del año.
    Podemos destacar esa tendencia con `geom_smooth()`:

    ```{r}
    daily %>% 
      ggplot(aes(date, resid)) + 
      geom_ref_line(h = 0) + 
      geom_line(colour = "grey50") + 
      geom_smooth(se = FALSE, span = 0.20)
    ```

    Hay menos vuelos en enero (y diciembre), y mas en verano 
    (May-Sep). No podemos hacer mucho cuantitativamente con este patron, porque  
    solo tenemos un año de datos. Pero podemos usar nuestro conocimiento 
    para pensar en posibles explicaciones.

### Efecto estacional de Sábado

Primero abordaremos nuestra falla para predecir con exactitud el numero de vuelos el sabado. Un buen lugar para empezar es 
volver a los numeros en bruto, enfocandonos en el sabado:

```{r}
daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n)) + 
    geom_point() + 
    geom_line() +
    scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

(He usado tanto puntos como líneas para dejar más claro que son los datos y qué es la interpolación.)

Yo sospecho que este patron es causado por las vacaciones de invierno: mucha gente va de vacaciones en verano, y a las personas no les importa viajar un sabado en sus vacaciones. Al mirar este grafico, podemos suponer que las vacaciones de verano son de principio de  junio a finales de Agosto. Parece que se alinea bastante bien con los [Terminos escolares del estado](http://schools.nyc.gov/Calendar/2013-2014+School+Year+Calendars.htm): las vacaciones de verano en 2013 fueron del 26 de junio hasta el 9 de septiembre. 

¿Por qué hay mas vuelos los sabados en primavera que en otoño? Le pregunté a algunos amigos estadounidenses y ellos me dijeron que es menos comun planificar vacaciones familiares durante el otoño porque debido a los grandes feriados de accion de gracia y navidad. No tenemos los datos para estar seguros, pero parece la hipotesis mas razonable.

Vamos a crear una variable "term" que capture aproximadamente las 3 reglas de colegios, y verifique nuestro trabajo con un gráfico:

```{r}
term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall") 
  )
}

daily <- daily %>% 
  mutate(term = term(date)) 

daily %>% 
  filter(wday == "Sat") %>% 
  ggplot(aes(date, n, colour = term)) +
  geom_point(alpha = 1/3) + 
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

(I manually tweaked the dates to get nice breaks in the plot. Using a visualisation to help you understand what your function is doing is a really powerful and general technique.)

It's useful to see how this new variable affects the other days of the week:

```{r}
daily %>% 
  ggplot(aes(wday, n, colour = term)) +
    geom_boxplot()
```

It looks like there is significant variation across the terms, so fitting a separate day of week effect for each term is reasonable. This improves our model, but not as much as we might hope:

```{r}
mod1 <- lm(n ~ wday, data = daily)
mod2 <- lm(n ~ wday * term, data = daily)

daily %>% 
  gather_residuals(without_term = mod1, with_term = mod2) %>% 
  ggplot(aes(date, resid, colour = model)) +
    geom_line(alpha = 0.75)
```

We can see the problem by overlaying the predictions from the model on to the raw data:

```{r}
grid <- daily %>% 
  data_grid(wday, term) %>% 
  add_predictions(mod2, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, colour = "red") + 
  facet_wrap(~ term)
```

Our model is finding the _mean_ effect, but we have a lot of big outliers, so mean tends to be far away from the typical value. We can alleviate this problem by using a model that is robust to the effect of outliers: `MASS::rlm()`. This greatly reduces the impact of the outliers on our estimates, and gives a model that does a good job of removing the day of week pattern:

```{r, warn = FALSE}
mod3 <- MASS::rlm(n ~ wday * term, data = daily)

daily %>% 
  add_residuals(mod3, "resid") %>% 
  ggplot(aes(date, resid)) + 
  geom_hline(yintercept = 0, size = 2, colour = "white") + 
  geom_line()
```

It's now much easier to see the long-term trend, and the positive and negative outliers.


### Computed variables

If you're experimenting with many models and many visualisations, it's a good idea to bundle the creation of variables up into a function so there's no chance of accidentally applying a different transformation in different places. For example, we could write:

```{r}
compute_vars <- function(data) {
  data %>% 
    mutate(
      term = term(date), 
      wday = wday(date, label = TRUE)
    )
}
```

Another option is to put the transformations directly in the model formula:

```{r}
wday2 <- function(x) wday(x, label = TRUE)
mod3 <- lm(n ~ wday2(date) * term(date), data = daily)
```

Either approach is reasonable. Making the transformed variable explicit is useful if you want to check your work, or use them in a visualisation. But you can't easily use transformations (like splines) that return multiple columns. Including the transformations in the model function makes life a little easier when you're working with many different datasets because the model is self contained.

### Time of year: an alternative approach

In the previous section we used our domain knowledge (how the US school term affects travel) to improve the model. An alternative to using our knowledge explicitly in the model is to give the data more room to speak. We could use a more flexible model and allow that to capture the pattern we're interested in. A simple linear trend isn't adequate, so we could try using a natural spline to fit a smooth curve across the year:

```{r}
library(splines)
mod <- MASS::rlm(n ~ wday * ns(date, 5), data = daily)

daily %>% 
  data_grid(wday, date = seq_range(date, n = 13)) %>% 
  add_predictions(mod) %>% 
  ggplot(aes(date, pred, colour = wday)) + 
    geom_line() +
    geom_point()
```

We see a strong pattern in the numbers of Saturday flights. This is reassuring, because we also saw that pattern in the raw data. It's a good sign when you get the same signal from different approaches.


### Exercises

1.  Use your Google sleuthing skills to brainstorm why there were fewer than
    expected flights on Jan 20, May 26, and Sep 1. (Hint: they all have the
    same explanation.) How would these days generalise to another year?

1.  What do the three days with high positive residuals represent?
    How would these days generalise to another year?

    ```{r}
    daily %>% 
      top_n(3, resid)
    ```

1.  Create a new variable that splits the `wday` variable into terms, but only
    for Saturdays, i.e. it should have `Thurs`, `Fri`, but `Sat-summer`, 
    `Sat-spring`, `Sat-fall`. How does this model compare with the model with 
    every combination of `wday` and `term`?
    
1.  Create a new `wday` variable that combines the day of week, term 
    (for Saturdays), and public holidays. What do the residuals of 
    that model look like?

1.  What happens if you fit a day of week effect that varies by month 
    (i.e. `n ~ wday * month`)? Why is this not very helpful? 

1.  What would you expect the model `n ~ wday + ns(date, 5)` to look like?
    Knowing what you know about the data, why would you expect it to be
    not particularly effective?

1.  We hypothesised that people leaving on Sundays are more likely to be 
    business travellers who need to be somewhere on Monday. Explore that 
    hypothesis by seeing how it breaks down based on distance and time: if 
    it's true, you'd expect to see more Sunday evening flights to places that 
    are far away.

1.  It's a little frustrating that Sunday and Saturday are on separate ends
    of the plot. Write a small function to set the levels of the 
    factor so that the week starts on Monday.

## Learning more about models

We have only scratched the absolute surface of modelling, but you have hopefully gained some simple, but general-purpose tools that you can use to improve your own data analyses. It's OK to start simple! As you've seen, even very simple models can make a dramatic difference in your ability to tease out interactions between variables.

These modelling chapters are even more opinionated than the rest of the book. I approach modelling from a somewhat different perspective to most others, and there is relatively little space devoted to it. Modelling really deserves a book on its own, so I'd highly recommend that you read at least one of these three books:

* *Statistical Modeling: A Fresh Approach* by Danny Kaplan,
  <http://www.mosaic-web.org/go/StatisticalModeling/>. This book provides 
  a gentle introduction to modelling, where you build your intuition,
  mathematical tools, and R skills in parallel. The book replaces a traditional
  "introduction to statistics" course, providing a curriculum that is up-to-date 
  and relevant to data science.

* *An Introduction to Statistical Learning* by Gareth James, Daniela Witten, 
  Trevor Hastie, and Robert Tibshirani, <http://www-bcf.usc.edu/~gareth/ISL/> 
  (available online for free). This book presents a family of modern modelling
  techniques collectively known as statistical learning.  For an even deeper
  understanding of the math behind the models, read the classic 
  *Elements of Statistical Learning* by Trevor Hastie, Robert Tibshirani, and
  Jerome Friedman, <http://statweb.stanford.edu/~tibs/ElemStatLearn/> (also
  available online for free).

* *Applied Predictive Modeling* by Max Kuhn and Kjell Johnson, 
  <http://appliedpredictivemodeling.com>. This book is a companion to the 
  __caret__ package and provides practical tools for dealing with real-life
  predictive modelling challenges.
